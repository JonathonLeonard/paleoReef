{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a5f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import imageio\n",
    "\n",
    "import pygmt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from numpy import deg2rad, sin, cos, meshgrid, gradient\n",
    "\n",
    "from fcts import *\n",
    "\n",
    "from pygmt.datasets import load_earth_relief\n",
    "grid = load_earth_relief(resolution=\"06m\", registration=\"gridline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b01414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation='../paleo_reef/paleomap/PALEOMAP_PlateModel.rot'\n",
    "plate='../paleo_reef/paleomap/PALEOMAP_PlatePolygons.gpml'\n",
    "\n",
    "Rearth = 6371.*1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d673832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def earth_radius(lat):\n",
    "    a = 6378137\n",
    "    b = 6356752.3142\n",
    "    e2 = 1 - (b**2/a**2)\n",
    "    lat = deg2rad(lat)\n",
    "    lat_gc = np.arctan( (1-e2)*np.tan(lat) )\n",
    "    r = (\n",
    "        (a * (1 - e2)**0.5) \n",
    "         / (1 - (e2 * np.cos(lat_gc)**2))**0.5 \n",
    "        )\n",
    "    return r\n",
    "\n",
    "def area_grid(lat, lon):\n",
    "    xlon, ylat = meshgrid(lon, lat)\n",
    "    R = earth_radius(ylat)\n",
    "    dlat = deg2rad(gradient(ylat, axis=0))\n",
    "    dlon = deg2rad(gradient(xlon, axis=1))\n",
    "    dy = dlat * R\n",
    "    dx = dlon * R * cos(deg2rad(ylat))\n",
    "    area = dy * dx\n",
    "    xda = xr.DataArray(\n",
    "        area,\n",
    "        dims=[\"latitude\", \"longitude\"],\n",
    "        coords={\"latitude\": lat, \"longitude\": lon},\n",
    "        attrs={\n",
    "            \"long_name\": \"area_per_pixel\",\n",
    "            \"description\": \"area per pixel\",\n",
    "            \"units\": \"m^2\",\n",
    "        },\n",
    "    )\n",
    "    return xda\n",
    "\n",
    "wmean = xr.open_dataset('../paleo_reef/sims/wmean_foster/0Ma.nc') #.fillna(0)\n",
    "da_area = area_grid(wmean['latitude'], wmean['longitude'])\n",
    "\n",
    "glon = da_area.longitude.values\n",
    "glat = da_area.latitude.values\n",
    "glons, glats = np.meshgrid(glon, glat)\n",
    "\n",
    "env = xr.open_dataset('../paleo_reef/env_var/enviVar0Ma_res1_foster.nc')\n",
    "regrid = xe.Regridder(env, wmean, 'bilinear', periodic=True, weights='data/regrid_elev.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258ee4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>meanArea</th>\n",
       "      <th>accRate</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permian</td>\n",
       "      <td>6200000.0</td>\n",
       "      <td>140</td>\n",
       "      <td>299</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triassic</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>230</td>\n",
       "      <td>251</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jurassic</td>\n",
       "      <td>8900000.0</td>\n",
       "      <td>167</td>\n",
       "      <td>199</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cretaceous</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>186</td>\n",
       "      <td>145</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paleogene</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>140</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neogene</td>\n",
       "      <td>9700000.0</td>\n",
       "      <td>177</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       period    meanArea  accRate  start  end\n",
       "0     Permian   6200000.0      140    299  251\n",
       "1    Triassic   7000000.0      230    251  199\n",
       "2    Jurassic   8900000.0      167    199  145\n",
       "3  Cretaceous  11000000.0      186    145   66\n",
       "4   Paleogene  12000000.0      140     66   23\n",
       "5     Neogene   9700000.0      177     23    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiessling03 = pd.read_csv('../paleo_reef/data/kiessling03.csv')\n",
    "kiessling03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52b7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructTime(tstart, tsim, depthlimit=False):\n",
    "\n",
    "    vtime = -np.arange(-tstart,0,dt)\n",
    "    env = xr.open_dataset(elevshare+str(tsim)+'Ma_res1_foster.nc')\n",
    "    \n",
    "    # Get the suitable habitats for a specific time\n",
    "    ds = xr.open_dataset(hydroshare+str(tstart)+'Ma.nc').copy()\n",
    "    regrid = xe.Regridder(env, ds, 'bilinear', periodic=True, weights='data/regrid_elev.nc')\n",
    "\n",
    "    fb = regrid(env.bathy).where(ds.wmean>0)\n",
    "    depth = fb.where(fb<0,-1).where(fb>-1400).where(ds.wmean>0)\n",
    "    meandepth = -depth.mean().values+0.\n",
    "    depth = depth.values.ravel().copy()\n",
    "    dataMean = ds['wmean'].where(fb>-1400).values.ravel().copy()\n",
    "    dataArea = da_area.values.ravel().copy()\n",
    "    \n",
    "    # Remove nan points and points with limited <1% suitability probability\n",
    "    mask = np.where(np.logical_and(~np.isnan(dataMean),dataMean>5))\n",
    "    wmean_val = dataMean[mask]\n",
    "    area_val = dataArea[mask]\n",
    "    depth_val = -depth[mask]\n",
    "    \n",
    "    lonlat = np.empty((len(wmean_val), 2))\n",
    "    lonlat[:, 0] = glons.ravel()[mask]\n",
    "    lonlat[:, 1] = glats.ravel()[mask]\n",
    "    \n",
    "    # Take the accumulation for the considered time slice\n",
    "    for k in range(len(kiessling03)):\n",
    "        if tstart < kiessling03['start'].iloc[k] and tstart >= kiessling03['end'].iloc[k]:\n",
    "            carbrate = kiessling03['accRate'].iloc[k]\n",
    "    \n",
    "    # Calculate the total area covered by carbonate km2\n",
    "    area_tot = ((wmean_val*area_val).sum()/1000)/1.e6\n",
    "    \n",
    "    # Calculate the volume of carbonate for 5 Myr in km3 for the time slice\n",
    "    # and limit the volume based on shelf depth\n",
    "    if depthlimit:\n",
    "        th_val = np.minimum(carbrate*wmean_val*5/1000,depth_val)\n",
    "    else:\n",
    "        th_val = carbrate*wmean_val*5/1000\n",
    "    vol_val = th_val*area_val*1.e-9 \n",
    "\n",
    "    mvwmean_val = wmean_val.copy()\n",
    "    mvarea_val = area_val.copy()\n",
    "    mvvol_val = vol_val.copy()\n",
    "    mvth_val = th_val.copy()\n",
    "    mvlonlat = lonlat.copy()\n",
    "    meshXYZ = polarToCartesian(Rearth, lonlat[:, 0], lonlat[:, 1])\n",
    "    \n",
    "    destroyWmean = []\n",
    "    destroyCarbTh = []\n",
    "    destroyCarbVol = []\n",
    "    destroyArea = []\n",
    "    destroy = []\n",
    "                                                              \n",
    "    for k in range(len(vtime)):\n",
    "        sXYZ = polarToCartesian(Rearth, mvlonlat[:, 0], mvlonlat[:, 1])\n",
    "        plateIds, vtree = getPlateIDs(vtime[k], mvlonlat, velshare, tree=None)\n",
    "        if k > 0:\n",
    "            notjumpsIDs = np.where(np.equal(pIDs, plateIds))[0]\n",
    "            jumpsIDs = np.where(np.not_equal(pIDs, plateIds))[0]\n",
    "            pIDs = plateIds.copy()[notjumpsIDs].copy()\n",
    "            destroy.append(len(jumpsIDs))\n",
    "            destroyArea.append(mvarea_val[jumpsIDs].sum()*1.e-6)\n",
    "            destroyWmean.append((mvarea_val[jumpsIDs]*mvwmean_val[jumpsIDs]).sum()*1.e-6/1000)\n",
    "            destroyCarbTh.append((mvth_val[jumpsIDs]).sum())\n",
    "            destroyCarbVol.append((mvvol_val[jumpsIDs]).sum())\n",
    "            \n",
    "            plateIds = plateIds[notjumpsIDs].copy()\n",
    "            sXYZ = sXYZ[notjumpsIDs,:].copy()\n",
    "            mvwmean_val = mvwmean_val[notjumpsIDs].copy()\n",
    "            mvarea_val = mvarea_val[notjumpsIDs].copy()\n",
    "            mvth_val = mvth_val[notjumpsIDs].copy()\n",
    "            mvvol_val = mvvol_val[notjumpsIDs].copy()\n",
    "            mvlonlat = np.empty((len(mvwmean_val),2))\n",
    "        else:\n",
    "            pIDs = plateIds.copy()\n",
    "            destroy.append(0)\n",
    "            destroyCarbTh.append(0)\n",
    "            destroyCarbVol.append(0)\n",
    "            destroyArea.append(0)\n",
    "            destroyWmean.append(0)\n",
    "        rotations = getRotations(vtime[k], dt, plateIds, rotation, plate)\n",
    "        movXYZ = movePlates(sXYZ, plateIds, rotations)\n",
    "        mvlonlat[:, 0] , mvlonlat[:, 1]  = cartesianToPolarCoords(movXYZ)\n",
    "\n",
    "    fdata = {\n",
    "        'time': -vtime,\n",
    "        'wmean': destroyWmean,\n",
    "        'area': destroyArea,\n",
    "        'vol': destroyCarbVol,\n",
    "        'thick': destroyCarbTh,\n",
    "        'nb': destroy,\n",
    "    }\n",
    "    destroyDf = pd.DataFrame(fdata)\n",
    "    \n",
    "    rdata = {\n",
    "        'lon': mvlonlat[:,0],\n",
    "        'lat': mvlonlat[:,1],\n",
    "        'wmean': mvwmean_val,\n",
    "        'vol': mvvol_val,\n",
    "        'thick': mvth_val,\n",
    "        'area': mvarea_val,\n",
    "    }\n",
    "    remainDf = pd.DataFrame(rdata)\n",
    "\n",
    "    preservedArea = [area_tot.sum()-np.cumsum(np.asarray(destroyWmean))[-1],area_tot.sum()]\n",
    "    preservedVol = [vol_val.sum()-np.cumsum(np.asarray(destroyCarbVol))[-1],vol_val.sum()]\n",
    "    preservedTh = [th_val.sum()-np.cumsum(np.asarray(destroyCarbTh))[-1],th_val.sum()]\n",
    "    ds.close()\n",
    "    env.close()\n",
    "    \n",
    "    return destroyDf, remainDf, preservedArea, preservedVol, preservedTh, meandepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9841cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct0Ma(depthlimit=False):\n",
    "    env = xr.open_dataset(elevshare+'0Ma_res1_foster.nc')\n",
    "    \n",
    "    ds = xr.open_dataset(hydroshare+'0Ma.nc').copy()\n",
    "    regrid = xe.Regridder(env, ds, 'bilinear', periodic=True, weights='data/regrid_elev.nc')\n",
    "\n",
    "    fb = regrid(env.bathy).where(ds.wmean>0)\n",
    "    depth = fb.where(fb<0,-1).where(fb>-1400).where(ds.wmean>0)\n",
    "    meandepth = -depth.mean().values+0.\n",
    "    depth = depth.values.ravel().copy()\n",
    "    dataMean = ds['wmean'].where(fb>-1400).values.ravel().copy()\n",
    "    dataArea = da_area.values.ravel().copy()\n",
    "    \n",
    "    # Remove nan points and points with limited <1% suitability probability\n",
    "    mask = np.where(np.logical_and(~np.isnan(dataMean),dataMean>5))\n",
    "    wmean_val = dataMean[mask]\n",
    "    area_val = dataArea[mask]\n",
    "    depth_val = -depth[mask]\n",
    "    lonlat = np.empty((len(wmean_val), 2))\n",
    "    lonlat[:, 0] = glons.ravel()[mask]\n",
    "    lonlat[:, 1] = glats.ravel()[mask]\n",
    "    \n",
    "    # Take the accumulation for the considered time slice\n",
    "    for k in range(len(kiessling03)):\n",
    "        if 0 < kiessling03['start'].iloc[k] and 0 >= kiessling03['end'].iloc[k]:\n",
    "            carbrate = kiessling03['accRate'].iloc[k]\n",
    "\n",
    "    # Calculate the total area covered by carbonate km2\n",
    "    area_tot = ((wmean_val*area_val).sum()/1000)/1.e6\n",
    "    \n",
    "    # Calculate the volume of carbonate for 5 Myr in km3 for the time slice\n",
    "    # and limit the volume based on shelf depth\n",
    "    if depthlimit:\n",
    "        th_val = np.minimum(carbrate*wmean_val*5/1000,depth_val)\n",
    "    else:\n",
    "        th_val = carbrate*wmean_val*5/1000\n",
    "    vol_val = th_val*area_val*1.e-9 \n",
    "\n",
    "    fdata = {\n",
    "        'time': [0],\n",
    "        'wmean': [0],\n",
    "        'area': [0],\n",
    "        'vol': [0],\n",
    "        'thick': [0],\n",
    "        'nb': [0],\n",
    "    }\n",
    "    destroyDf = pd.DataFrame(fdata)\n",
    "    \n",
    "    rdata = {\n",
    "        'lon': lonlat[:,0],\n",
    "        'lat': lonlat[:,1],\n",
    "        'wmean': wmean_val,\n",
    "        'vol': vol_val,\n",
    "        'thick': th_val,\n",
    "        'area': area_val,\n",
    "    }\n",
    "    remainDf = pd.DataFrame(rdata)\n",
    "    \n",
    "    \n",
    "    preservedArea = [area_tot.sum(),area_tot.sum()]\n",
    "    preservedVol = [vol_val.sum(),vol_val.sum()]\n",
    "    preservedTh = [th_val.sum(),th_val.sum()]\n",
    "    ds.close()\n",
    "    env.close()\n",
    "    \n",
    "    return destroyDf, remainDf, preservedArea, preservedVol, preservedTh, meandepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7134929",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 5\n",
    "ntimes = -np.arange(-265,0,dt)\n",
    "\n",
    "curve = 'foster'\n",
    "# curve = 'smooth'\n",
    "hydroshare = '../paleo_reef/sims/wmean_'+curve+'/'\n",
    "elevshare = '../paleo_reef/env_var/enviVar'\n",
    "edshare = '../paleo_reef/sims/erorate/'\n",
    "velshare = '../paleo_reef/paleomap/pID/pID'\n",
    "\n",
    "combt = pd.read_csv('../paleo_reef/data/combine_time.csv')\n",
    "simt = combt['clim'].values[55:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c3166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruct time  265  Ma\n",
      "Reconstruct time  260  Ma\n",
      "Reconstruct time  255  Ma\n",
      "Reconstruct time  250  Ma\n",
      "Reconstruct time  245  Ma\n",
      "Reconstruct time  240  Ma\n",
      "Reconstruct time  235  Ma\n",
      "Reconstruct time  230  Ma\n",
      "Reconstruct time  225  Ma\n",
      "Reconstruct time  220  Ma\n",
      "Reconstruct time  215  Ma\n",
      "Reconstruct time  210  Ma\n",
      "Reconstruct time  205  Ma\n",
      "Reconstruct time  200  Ma\n",
      "Reconstruct time  195  Ma\n",
      "Reconstruct time  190  Ma\n",
      "Reconstruct time  185  Ma\n",
      "Reconstruct time  180  Ma\n",
      "Reconstruct time  175  Ma\n",
      "Reconstruct time  170  Ma\n",
      "Reconstruct time  165  Ma\n",
      "Reconstruct time  160  Ma\n",
      "Reconstruct time  155  Ma\n",
      "Reconstruct time  150  Ma\n",
      "Reconstruct time  145  Ma\n",
      "Reconstruct time  140  Ma\n",
      "Reconstruct time  135  Ma\n",
      "Reconstruct time  130  Ma\n",
      "Reconstruct time  125  Ma\n",
      "Reconstruct time  120  Ma\n",
      "Reconstruct time  115  Ma\n",
      "Reconstruct time  110  Ma\n",
      "Reconstruct time  105  Ma\n",
      "Reconstruct time  100  Ma\n",
      "Reconstruct time  95  Ma\n",
      "Reconstruct time  90  Ma\n",
      "Reconstruct time  85  Ma\n",
      "Reconstruct time  80  Ma\n",
      "Reconstruct time  75  Ma\n",
      "Reconstruct time  70  Ma\n",
      "Reconstruct time  65  Ma\n",
      "Reconstruct time  60  Ma\n",
      "Reconstruct time  55  Ma\n",
      "Reconstruct time  50  Ma\n",
      "Reconstruct time  45  Ma\n",
      "Reconstruct time  40  Ma\n",
      "Reconstruct time  35  Ma\n",
      "Reconstruct time  30  Ma\n",
      "Reconstruct time  25  Ma\n",
      "Reconstruct time  20  Ma\n",
      "Reconstruct time  15  Ma\n",
      "Reconstruct time  10  Ma\n",
      "Reconstruct time  5  Ma\n",
      "Reconstruct time  0  Ma\n"
     ]
    }
   ],
   "source": [
    "destroyDf = [] \n",
    "remainDf = [] \n",
    "presArea = []\n",
    "presVol = []\n",
    "presTh = []\n",
    "meandepth = []\n",
    "depthlimit = False\n",
    "\n",
    "for t in range(len(ntimes)):\n",
    "    print('Reconstruct time ',int(ntimes[t]),' Ma')\n",
    "    detr, rem, prs_area, prs_vol, prs_th, md = reconstructTime(int(ntimes[t]),int(simt[t]),depthlimit)\n",
    "    destroyDf.append(detr)\n",
    "    remainDf.append(rem)\n",
    "    presArea.append(prs_area)\n",
    "    presVol.append(prs_vol)\n",
    "    presTh.append(prs_th)\n",
    "    meandepth.append(md)\n",
    "    \n",
    "print('Reconstruct time  0  Ma')\n",
    "detr, rem, prs_area, prs_vol, prs_th,md = reconstruct0Ma(depthlimit)\n",
    "destroyDf.append(detr)\n",
    "remainDf.append(rem)\n",
    "presArea.append(prs_area)\n",
    "presVol.append(prs_vol)\n",
    "presTh.append(prs_th)\n",
    "meandepth.append(md)\n",
    "\n",
    "# Save data on disk\n",
    "stf = 'pickle/nolimit_'\n",
    "if depthlimit:\n",
    "    stf = 'pickle/limit_'\n",
    "    \n",
    "with open(stf+'destroy_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(destroyDf, f)\n",
    "    \n",
    "with open(stf+'remain_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(remainDf, f)\n",
    "    \n",
    "with open(stf+'area_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(presArea, f)\n",
    "\n",
    "with open(stf+'vol_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(presVol, f)\n",
    "    \n",
    "with open(stf+'th_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(presTh, f)\n",
    "    \n",
    "with open(stf+'meandepth_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(meandepth, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d707ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 5\n",
    "ntimes = -np.arange(-265,0,dt)\n",
    "\n",
    "curve = 'smooth'\n",
    "hydroshare = '../paleo_reef/sims/wmean_'+curve+'/'\n",
    "elevshare = '../paleo_reef/env_var/enviVar'\n",
    "edshare = '../paleo_reef/sims/erorate/'\n",
    "velshare = '../paleo_reef/paleomap/pID/pID'\n",
    "\n",
    "combt = pd.read_csv('../paleo_reef/data/combine_time.csv')\n",
    "simt = combt['clim'].values[55:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c68870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruct time  265  Ma\n",
      "Reconstruct time  260  Ma\n",
      "Reconstruct time  255  Ma\n",
      "Reconstruct time  250  Ma\n",
      "Reconstruct time  245  Ma\n",
      "Reconstruct time  240  Ma\n",
      "Reconstruct time  235  Ma\n",
      "Reconstruct time  230  Ma\n",
      "Reconstruct time  225  Ma\n",
      "Reconstruct time  220  Ma\n",
      "Reconstruct time  215  Ma\n",
      "Reconstruct time  210  Ma\n",
      "Reconstruct time  205  Ma\n",
      "Reconstruct time  200  Ma\n",
      "Reconstruct time  195  Ma\n",
      "Reconstruct time  190  Ma\n",
      "Reconstruct time  185  Ma\n",
      "Reconstruct time  180  Ma\n",
      "Reconstruct time  175  Ma\n",
      "Reconstruct time  170  Ma\n",
      "Reconstruct time  165  Ma\n",
      "Reconstruct time  160  Ma\n",
      "Reconstruct time  155  Ma\n",
      "Reconstruct time  150  Ma\n",
      "Reconstruct time  145  Ma\n",
      "Reconstruct time  140  Ma\n",
      "Reconstruct time  135  Ma\n",
      "Reconstruct time  130  Ma\n",
      "Reconstruct time  125  Ma\n",
      "Reconstruct time  120  Ma\n",
      "Reconstruct time  115  Ma\n",
      "Reconstruct time  110  Ma\n",
      "Reconstruct time  105  Ma\n",
      "Reconstruct time  100  Ma\n",
      "Reconstruct time  95  Ma\n",
      "Reconstruct time  90  Ma\n",
      "Reconstruct time  85  Ma\n",
      "Reconstruct time  80  Ma\n",
      "Reconstruct time  75  Ma\n",
      "Reconstruct time  70  Ma\n",
      "Reconstruct time  65  Ma\n",
      "Reconstruct time  60  Ma\n",
      "Reconstruct time  55  Ma\n",
      "Reconstruct time  50  Ma\n",
      "Reconstruct time  45  Ma\n",
      "Reconstruct time  40  Ma\n",
      "Reconstruct time  35  Ma\n",
      "Reconstruct time  30  Ma\n",
      "Reconstruct time  25  Ma\n",
      "Reconstruct time  20  Ma\n",
      "Reconstruct time  15  Ma\n",
      "Reconstruct time  10  Ma\n",
      "Reconstruct time  5  Ma\n",
      "Reconstruct time  0  Ma\n"
     ]
    }
   ],
   "source": [
    "destroyDf = [] \n",
    "remainDf = [] \n",
    "presArea = []\n",
    "presVol = []\n",
    "presTh = []\n",
    "meandepth = []\n",
    "depthlimit = False\n",
    "\n",
    "for t in range(len(ntimes)):\n",
    "    print('Reconstruct time ',int(ntimes[t]),' Ma')\n",
    "    detr, rem, prs_area, prs_vol, prs_th, md = reconstructTime(int(ntimes[t]),int(simt[t]),depthlimit)\n",
    "    destroyDf.append(detr)\n",
    "    remainDf.append(rem)\n",
    "    presArea.append(prs_area)\n",
    "    presVol.append(prs_vol)\n",
    "    presTh.append(prs_th)\n",
    "    meandepth.append(md)\n",
    "    \n",
    "print('Reconstruct time  0  Ma')\n",
    "detr, rem, prs_area, prs_vol, prs_th,md = reconstruct0Ma(depthlimit)\n",
    "destroyDf.append(detr)\n",
    "remainDf.append(rem)\n",
    "presArea.append(prs_area)\n",
    "presVol.append(prs_vol)\n",
    "presTh.append(prs_th)\n",
    "meandepth.append(md)\n",
    "\n",
    "# Save data on disk\n",
    "stf = 'pickle/nolimit_'\n",
    "if depthlimit:\n",
    "    stf = 'pickle/limit_'\n",
    "    \n",
    "with open(stf+'destroy_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(destroyDf, f)\n",
    "    \n",
    "with open(stf+'remain_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(remainDf, f)\n",
    "    \n",
    "with open(stf+'area_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(presArea, f)\n",
    "\n",
    "with open(stf+'vol_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(presVol, f)\n",
    "    \n",
    "with open(stf+'th_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(presTh, f)\n",
    "    \n",
    "with open(stf+'meandepth_'+curve+'.pkl', 'wb') as f:\n",
    "    pickle.dump(meandepth, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307d8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc3e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe46610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
